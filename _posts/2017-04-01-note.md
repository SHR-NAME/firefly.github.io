#### IM 相关
- 1.1 IM通信的机制，如何保证可靠连接？

  websocket 协议 ws://...
  他是一个基于tcp的应用层协议

  这里边设置 TCP 连接建立的三次握手，这层封装的是端口号,源端口和目标端口。
  1.客户端发送 syn = 1 建立连接的请求。seq number = 0；
  2.服务器端收到syn =1 的请求之后，会将ack = 1，发送给客户端。
  3.客户端收到服务器端ack =1 的请求之后，把 seq number = 1。
  连接建立成功

  具体请求抓包分析可发现：
  客户端会先发送一个特殊的HTTP请求，在请求头参数中添加Connection:Upgrade 和 Upgrade:websocket,来协商需要更换的协议，
  服务器收到之后回复code：101 确认理解客户端请求，并在回复包中添加Connection:Upgrade 和 Upgrade:websocket字段。

  服务器采用tcp socket 的方式进行数据的接收

  有一个问题 websocket 和socket 区别？
  websocket 是基于tcp的应用层协议，而socket是对tcp/ip 层的抽象接口。
  websocket 采用frame 帧的形式进行数据传输，并且是全双工的

  socket 开发 rpc

- 1.2 IM相关数据库表的存储如何实现？
  常见的数据库表有
  message表 常见字段 msg_id,msg_type,msg_body,attach_url,msg_status,read_status,from_id,to_id,date.
  converstion表 常见字段 group_id,icon,group_name,last_msg,initseqId,seqId,

- 1.3 如何提高收发消息的效率？低延迟 传输快Netty 如何做到高并发，高性能的

> Netty是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。
以高并发（Reactor模型），低延迟-传输快-零拷贝技术，可支持定制多种协议著称。

Netty 核心组建

**Channel**

Netty 网络操作抽象类，包括基本的I/O操作，如bind connect read write等，大大降低了直接使用socket类
的复杂性。

    1. NioSocketChannel 异步的客户端TCP socket连接
    2. NioServerSocketChannel 异步的服务器端TCP socket连接
    3. NioDatagramChannel 异步的UPD连接
    **EventLoop**

EventLoop 事件循环接口，负责监听网络事件并调用事件处理器进行相关I/O操作的处理。
EventLoop 内部持有NIO中的Selector，Channel将会被注册到Eventloop中，一个EventLoop可以监听
多个Channel，EventLoop是实现IO多路复用的核心，可以看作是Reactor模型中的mainReactor。

**ChannelFuture**

Netty中所有的IO操作都是异步的，不能立刻得知消息是否被正确处理。

Channel会注册到EventLoop中后会立即返回一个ChannelFuture对象，可以通过ChannelFuture
的addListener注册GenericFutureListener监听器来进行结果的监听。

**ChannelHandler** 消息的具体处理器
负责各种业务，读写事件，连接，解码编码，数据转换，业务逻辑等等，处理完毕之后将数据转发到ChannelPipeline中
的下一个ChannelHandler。

ChannelInboundHandler 处理入站io事件
ChannelOutboundHandler 处理出站io事件

或者使用适配器类，更加方便
ChannelInboundHandlerAdapter 处理入站io事件
ChannelOutboundHandlerAdapter 处理出站io事件
ChannelDuplexHandler用于处理入站和出站事件

**ChannelPipeline**  Netty中每个Channel都有且仅有一个ChannelPipeline与之对应。
是一个链表，里边放的是ChannelHandler，可以在 ChannelPipeline 上通过 addLast() 方法添加一个或者多个ChannelHandler ，因为一个数据或者事件可能会被多个 Handler 处理。当一个 ChannelHandler 处理完之后就将数据交给下一个 ChannelHandler 。

在执行时，入站事件会从链表head往后传递到最后一个入站的handler（ChannelInboundHandler类型），出站事件会从链表tail往前传递到最前一个出站的handler（ChannelOutboundHandler类型），两种类型的handler在执行时互不干扰。如果Handler同时属于入站、出站Handler，则都会执行一次。

![p-1](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cdcc1a59ab02429d9ebcdc82a9a9042a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

ChannelHandlerContext 保存Channel相关的上下文信息。将Handler和Pipeline联系起来，实际上ChannelPipeline中直接存的是
ChannelHandlerContext，而每个ChannelHandlerContext里边包含着ChannelHandler。

![p-2](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4e5182ea2c7d419a8e2127f0b6aed7a7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

**EventLoopGroup**

事件循环组，里边包含多个事件循环Eventloop。每个EventLoop通常包含1个Selector和1个事件循环线程，一个Eventloop可以绑定多个Channel，但是每个Channel只能被
一个EventLoop绑定，这样连接的IO事件就在专门的线程上处理，保证线程安全。

Netty Server端包含一个boss 和 一个worker，职责如下：
boss ：
1. select监听accept事件。
2. 处理到来的accept事件，与Client建立连接，生成一个SocketChannel，并将SocketChannel注册到某个
   Worker NioEventLoop的Selector上。
3. 处理任务队列中的任务，runAllTasks。任务队列中的任务包括用户调用eventloop.execute或schedule执行的任务，或者其它线程提交到该eventloop的任务。
   worker：
1. select监听read，write事件。
2. 处理到来的read，write事件，在NioSocketChannel可读，可写事件发生时进行处理。
3. 处理任务队列中的任务，runAllTasks。

    **TCP 粘包/拆包 的原因和解决办法**

原因：TCP是以流的方式来处理数据，底层会有一个缓冲区，一个完整的较大的包可能会被TCP拆分成多个包进行发送，也可能把多个小的包封装成一个大的数据包发送。
报头的选项字段有MSS（Maximum Segment Size，最大报文段大小）字段，规定一个TCP包最大可传输的字节数，一般是1500-20-20=1460字节，大于该大小时将发生拆包。

解决办法：使用Netty自带的解码器
1. LineBasedFrameDecoder : 发送端发送数据包的时候，每个数据包之间以换行符作为分隔，即\n或者\r\n，其工作原理是它依次遍历 ByteBuf 中的可读字节，判断是否有换行符，然后进行相应的截取。
2. DelimiterBasedFrameDecoder : 可以自定义分隔符解码器，其实际上是一种特殊的DelimiterBasedFrameDecoder 解码器。
3. FixedLengthFrameDecoder: 固定长度解码器，它能够按照指定的长度对消息进行相应的拆包。需要约定每一个包的固定大小。
4. LengthFieldBasedFrameDecoder：将消息分为消息头和消息体。在头部中保存有当前整个消息的长度，只有在读取到足够长度的消息之后才算是读到了一个完整的消息。

通过自定义协议进行粘包和拆包处理。

    **长链接和心跳机制**
在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，它们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入心跳机制 。
心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle 状态时，客户端或服务器就会发送一个特殊的数据包给对方，当接收方收到这个数据报文后，也立即发送一个特殊的数据报文，回应发送方，此即一个 PING-PONG 交互。所以，当某一端收到心跳消息后，就知道了对方仍然在线，这就确保 TCP 连接的有效性

    **Netty零拷贝技术**
> 零拷贝（Zero-Copy）是一种 I/O 操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间。目前只有在使用 NIO 和 Epoll 传输时才可使用该特性。

传统I/O 工作方式
![p-3](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f6c3a1a5de3640aeb3b8a8771ff3a810~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

零拷贝技术原理：
零拷贝主要是用来解决操作系统在处理 I/O 操作时，频繁复制数据的问题。关于零拷贝主要技术有 mmap+write、sendfile和splice等几种方式。

有现代操作系统都使用虚拟内存，使用虚拟地址取代物理地址，主要有以下几点好处：

多个虚拟内存可以指向同一个物理地址。
虚拟内存空间可以远远大于物理内存空间。

利用上述的第一条特性可以优化，可以把内核空间和用户空间的虚拟地址映射到同一个物理地址，这样在 I/O 操作时就不需要来回复制了。

    **mmap/write 方式**
![p-4](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d3747aca11884a1a85708c0163c79a99~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
整个流程的核心区别就是，把数据读取到内核缓冲区后，应用程序进行写入操作时，直接把内核的Read Buffer的数据复制到Socket Buffer以便写入，这次内核之间的复制也是需要CPU的参与的

    **sendfile**

![p-5](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d221a3a90a754ca9842f6324455638ea~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
sendfile方式只有三次数据复制（其中只有一次 CPU COPY）以及2次上下文切换。
- 1.4 总结 Java NIO
  1.Selectors
  2.Channels
  3.Buffers
  4.Selectionkeys

  这里边设计到Reactor反应器模式，简单说明一下

  1、Server 端负责 Selector 的创建，并负责监听从client 来的连接，在一个loop循环中监听
  如果监听到了，就通过dispath分发出去，入参selector和socket到acceptor中，在acceptor中的run方法中，
  把selector和channel作为参数传递会开启一个Handler处理接收器里边的请求，从而进行处理。